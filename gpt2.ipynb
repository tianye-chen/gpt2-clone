{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "50a4b129",
   "metadata": {},
   "outputs": [],
   "source": [
    "from SimpleGPT import SimpleGPT\n",
    "from llm_utils import text_generation, train\n",
    "from InstructionDataset import InstructionDataset, collate_fn, to_alpaca_format\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from functools import partial\n",
    "import tiktoken\n",
    "import json\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a35430ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_DIR = \"./117M\"\n",
    "USE_MLA = True\n",
    "GPT2_CONFIG_124M = {\n",
    "     \"vocab_size\": 50257,\n",
    "     \"context_length\": 256,\n",
    "     \"emb_dim\": 768,\n",
    "     \"n_heads\": 12,\n",
    "     \"n_layers\": 12,\n",
    "     \"dropout_rate\": 0.1,\n",
    "     'batch_size': 12,\n",
    "     'd_R': 16, # For Multihead Latent Attention\n",
    "     'd_c': 256, # For Multihead Latent Attention\n",
    "     \"qkv_bias\": False \n",
    "}\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = SimpleGPT(GPT2_CONFIG_124M, use_mla=USE_MLA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "36b2ae6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda\n"
     ]
    }
   ],
   "source": [
    "print(f'Using {DEVICE}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1eb64f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since the original model is trained with TensorFlow, we read it using TensorFlow\n",
    "\n",
    "tf_checkpoint_path = tf.train.latest_checkpoint(MODEL_DIR)\n",
    "tf_model_settings = json.load(open(os.path.join(MODEL_DIR, \"hparams.json\")))\n",
    "\n",
    "params = {\"blocks\": [{} for _ in range(tf_model_settings['n_layer'])]}\n",
    "\n",
    "for name, _ in tf.train.list_variables(tf_checkpoint_path):\n",
    "    var = np.squeeze(tf.train.load_variable(tf_checkpoint_path, name))\n",
    "    var_name_no_prefix = name.split(\"/\")[1:]\n",
    "    \n",
    "    target_dict = params\n",
    "    \n",
    "    if var_name_no_prefix[0].startswith(\"h\"):\n",
    "        layer_id = int(var_name_no_prefix[0][1:])\n",
    "        target_dict = params[\"blocks\"][layer_id]\n",
    "    \n",
    "    for key in var_name_no_prefix[1:-1]:\n",
    "        target_dict = target_dict.setdefault(key, {})\n",
    "    \n",
    "    last_key = var_name_no_prefix[-1]\n",
    "    target_dict[last_key] = var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ce56ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.pos_emb.weight = nn.Parameter(torch.tensor(params['wpe']))\n",
    "model.token_emb.weight = nn.Parameter(torch.tensor(params['wte']))\n",
    "\n",
    "# Load pretrained model parameters\n",
    "for i in range(len(params['blocks'])):\n",
    "    q_w, k_w, v_w = np.split((params['blocks'][i]['attn']['c_attn'])['w'], 3, axis=-1)\n",
    "    q_b, k_b, v_b = np.split((params['blocks'][i]['attn']['c_attn'])['b'], 3, axis=-1)\n",
    "    \n",
    "    if not USE_MLA:\n",
    "        model.transformer_blocks[i].attn.W_q.weight = nn.Parameter(torch.tensor(q_w.T))\n",
    "        model.transformer_blocks[i].attn.W_k.weight = nn.Parameter(torch.tensor(k_w.T))\n",
    "        model.transformer_blocks[i].attn.W_v.weight = nn.Parameter(torch.tensor(v_w.T))\n",
    "        \n",
    "        model.transformer_blocks[i].attn.W_q.bias = nn.Parameter(torch.tensor(q_b))\n",
    "        model.transformer_blocks[i].attn.W_k.bias = nn.Parameter(torch.tensor(k_b))\n",
    "        model.transformer_blocks[i].attn.W_v.bias = nn.Parameter(torch.tensor(v_b))\n",
    "    \n",
    "    model.transformer_blocks[i].attn.output_projection.weight = nn.Parameter(torch.tensor(params['blocks'][i]['attn']['c_proj']['w'].T))\n",
    "    model.transformer_blocks[i].attn.output_projection.bias = nn.Parameter(torch.tensor(params['blocks'][i]['attn']['c_proj']['b']))\n",
    "    \n",
    "    model.transformer_blocks[i].ff_block[1].weight = nn.Parameter(torch.tensor(params['blocks'][i]['mlp']['c_fc']['w'].T))\n",
    "    model.transformer_blocks[i].ff_block[1].bias = nn.Parameter(torch.tensor(params['blocks'][i]['mlp']['c_fc']['b']))\n",
    "    model.transformer_blocks[i].ff_block[3].weight = nn.Parameter(torch.tensor(params['blocks'][i]['mlp']['c_proj']['w'].T))\n",
    "    model.transformer_blocks[i].ff_block[3].bias = nn.Parameter(torch.tensor(params['blocks'][i]['mlp']['c_proj']['b']))\n",
    "    \n",
    "    model.transformer_blocks[i].attn_block[0].scale = nn.Parameter(torch.tensor(params['blocks'][i]['ln_1']['g']))\n",
    "    model.transformer_blocks[i].attn_block[0].shift = nn.Parameter(torch.tensor(params['blocks'][i]['ln_1']['b']))\n",
    "    model.transformer_blocks[i].ff_block[0].scale = nn.Parameter(torch.tensor(params['blocks'][i]['ln_2']['g']))\n",
    "    model.transformer_blocks[i].ff_block[0].shift = nn.Parameter(torch.tensor(params['blocks'][i]['ln_2']['b']))\n",
    "\n",
    "model.final_norm.scale = nn.Parameter(torch.tensor(params['g']))\n",
    "model.final_norm.shift = nn.Parameter(torch.tensor(params['b']))\n",
    "model.out.weight = nn.Parameter(torch.tensor(params['wte']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "52e41d28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimpleGPT(\n",
      "  (token_emb): Embedding(50257, 768)\n",
      "  (pos_emb): Embedding(256, 768)\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (transformer_blocks): Sequential(\n",
      "    (0): Transformer(\n",
      "      (attn): MultiheadLatentAttention(\n",
      "        (W_DKV): Linear(in_features=768, out_features=256, bias=False)\n",
      "        (W_DQ): Linear(in_features=768, out_features=256, bias=False)\n",
      "        (W_UK): Linear(in_features=256, out_features=768, bias=False)\n",
      "        (W_UV): Linear(in_features=256, out_features=768, bias=False)\n",
      "        (W_UQ): Linear(in_features=256, out_features=768, bias=False)\n",
      "        (W_KR): Linear(in_features=768, out_features=16, bias=False)\n",
      "        (W_QR): Linear(in_features=256, out_features=192, bias=False)\n",
      "        (output_projection): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (attn_block): Sequential(\n",
      "        (0): LayerNorm()\n",
      "        (1): MultiheadLatentAttention(\n",
      "          (W_DKV): Linear(in_features=768, out_features=256, bias=False)\n",
      "          (W_DQ): Linear(in_features=768, out_features=256, bias=False)\n",
      "          (W_UK): Linear(in_features=256, out_features=768, bias=False)\n",
      "          (W_UV): Linear(in_features=256, out_features=768, bias=False)\n",
      "          (W_UQ): Linear(in_features=256, out_features=768, bias=False)\n",
      "          (W_KR): Linear(in_features=768, out_features=16, bias=False)\n",
      "          (W_QR): Linear(in_features=256, out_features=192, bias=False)\n",
      "          (output_projection): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (2): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (ff_block): Sequential(\n",
      "        (0): LayerNorm()\n",
      "        (1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        (2): GELU(approximate='none')\n",
      "        (3): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        (4): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (1): Transformer(\n",
      "      (attn): MultiheadLatentAttention(\n",
      "        (W_DKV): Linear(in_features=768, out_features=256, bias=False)\n",
      "        (W_DQ): Linear(in_features=768, out_features=256, bias=False)\n",
      "        (W_UK): Linear(in_features=256, out_features=768, bias=False)\n",
      "        (W_UV): Linear(in_features=256, out_features=768, bias=False)\n",
      "        (W_UQ): Linear(in_features=256, out_features=768, bias=False)\n",
      "        (W_KR): Linear(in_features=768, out_features=16, bias=False)\n",
      "        (W_QR): Linear(in_features=256, out_features=192, bias=False)\n",
      "        (output_projection): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (attn_block): Sequential(\n",
      "        (0): LayerNorm()\n",
      "        (1): MultiheadLatentAttention(\n",
      "          (W_DKV): Linear(in_features=768, out_features=256, bias=False)\n",
      "          (W_DQ): Linear(in_features=768, out_features=256, bias=False)\n",
      "          (W_UK): Linear(in_features=256, out_features=768, bias=False)\n",
      "          (W_UV): Linear(in_features=256, out_features=768, bias=False)\n",
      "          (W_UQ): Linear(in_features=256, out_features=768, bias=False)\n",
      "          (W_KR): Linear(in_features=768, out_features=16, bias=False)\n",
      "          (W_QR): Linear(in_features=256, out_features=192, bias=False)\n",
      "          (output_projection): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (2): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (ff_block): Sequential(\n",
      "        (0): LayerNorm()\n",
      "        (1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        (2): GELU(approximate='none')\n",
      "        (3): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        (4): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (2): Transformer(\n",
      "      (attn): MultiheadLatentAttention(\n",
      "        (W_DKV): Linear(in_features=768, out_features=256, bias=False)\n",
      "        (W_DQ): Linear(in_features=768, out_features=256, bias=False)\n",
      "        (W_UK): Linear(in_features=256, out_features=768, bias=False)\n",
      "        (W_UV): Linear(in_features=256, out_features=768, bias=False)\n",
      "        (W_UQ): Linear(in_features=256, out_features=768, bias=False)\n",
      "        (W_KR): Linear(in_features=768, out_features=16, bias=False)\n",
      "        (W_QR): Linear(in_features=256, out_features=192, bias=False)\n",
      "        (output_projection): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (attn_block): Sequential(\n",
      "        (0): LayerNorm()\n",
      "        (1): MultiheadLatentAttention(\n",
      "          (W_DKV): Linear(in_features=768, out_features=256, bias=False)\n",
      "          (W_DQ): Linear(in_features=768, out_features=256, bias=False)\n",
      "          (W_UK): Linear(in_features=256, out_features=768, bias=False)\n",
      "          (W_UV): Linear(in_features=256, out_features=768, bias=False)\n",
      "          (W_UQ): Linear(in_features=256, out_features=768, bias=False)\n",
      "          (W_KR): Linear(in_features=768, out_features=16, bias=False)\n",
      "          (W_QR): Linear(in_features=256, out_features=192, bias=False)\n",
      "          (output_projection): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (2): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (ff_block): Sequential(\n",
      "        (0): LayerNorm()\n",
      "        (1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        (2): GELU(approximate='none')\n",
      "        (3): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        (4): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (3): Transformer(\n",
      "      (attn): MultiheadLatentAttention(\n",
      "        (W_DKV): Linear(in_features=768, out_features=256, bias=False)\n",
      "        (W_DQ): Linear(in_features=768, out_features=256, bias=False)\n",
      "        (W_UK): Linear(in_features=256, out_features=768, bias=False)\n",
      "        (W_UV): Linear(in_features=256, out_features=768, bias=False)\n",
      "        (W_UQ): Linear(in_features=256, out_features=768, bias=False)\n",
      "        (W_KR): Linear(in_features=768, out_features=16, bias=False)\n",
      "        (W_QR): Linear(in_features=256, out_features=192, bias=False)\n",
      "        (output_projection): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (attn_block): Sequential(\n",
      "        (0): LayerNorm()\n",
      "        (1): MultiheadLatentAttention(\n",
      "          (W_DKV): Linear(in_features=768, out_features=256, bias=False)\n",
      "          (W_DQ): Linear(in_features=768, out_features=256, bias=False)\n",
      "          (W_UK): Linear(in_features=256, out_features=768, bias=False)\n",
      "          (W_UV): Linear(in_features=256, out_features=768, bias=False)\n",
      "          (W_UQ): Linear(in_features=256, out_features=768, bias=False)\n",
      "          (W_KR): Linear(in_features=768, out_features=16, bias=False)\n",
      "          (W_QR): Linear(in_features=256, out_features=192, bias=False)\n",
      "          (output_projection): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (2): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (ff_block): Sequential(\n",
      "        (0): LayerNorm()\n",
      "        (1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        (2): GELU(approximate='none')\n",
      "        (3): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        (4): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (4): Transformer(\n",
      "      (attn): MultiheadLatentAttention(\n",
      "        (W_DKV): Linear(in_features=768, out_features=256, bias=False)\n",
      "        (W_DQ): Linear(in_features=768, out_features=256, bias=False)\n",
      "        (W_UK): Linear(in_features=256, out_features=768, bias=False)\n",
      "        (W_UV): Linear(in_features=256, out_features=768, bias=False)\n",
      "        (W_UQ): Linear(in_features=256, out_features=768, bias=False)\n",
      "        (W_KR): Linear(in_features=768, out_features=16, bias=False)\n",
      "        (W_QR): Linear(in_features=256, out_features=192, bias=False)\n",
      "        (output_projection): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (attn_block): Sequential(\n",
      "        (0): LayerNorm()\n",
      "        (1): MultiheadLatentAttention(\n",
      "          (W_DKV): Linear(in_features=768, out_features=256, bias=False)\n",
      "          (W_DQ): Linear(in_features=768, out_features=256, bias=False)\n",
      "          (W_UK): Linear(in_features=256, out_features=768, bias=False)\n",
      "          (W_UV): Linear(in_features=256, out_features=768, bias=False)\n",
      "          (W_UQ): Linear(in_features=256, out_features=768, bias=False)\n",
      "          (W_KR): Linear(in_features=768, out_features=16, bias=False)\n",
      "          (W_QR): Linear(in_features=256, out_features=192, bias=False)\n",
      "          (output_projection): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (2): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (ff_block): Sequential(\n",
      "        (0): LayerNorm()\n",
      "        (1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        (2): GELU(approximate='none')\n",
      "        (3): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        (4): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (5): Transformer(\n",
      "      (attn): MultiheadLatentAttention(\n",
      "        (W_DKV): Linear(in_features=768, out_features=256, bias=False)\n",
      "        (W_DQ): Linear(in_features=768, out_features=256, bias=False)\n",
      "        (W_UK): Linear(in_features=256, out_features=768, bias=False)\n",
      "        (W_UV): Linear(in_features=256, out_features=768, bias=False)\n",
      "        (W_UQ): Linear(in_features=256, out_features=768, bias=False)\n",
      "        (W_KR): Linear(in_features=768, out_features=16, bias=False)\n",
      "        (W_QR): Linear(in_features=256, out_features=192, bias=False)\n",
      "        (output_projection): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (attn_block): Sequential(\n",
      "        (0): LayerNorm()\n",
      "        (1): MultiheadLatentAttention(\n",
      "          (W_DKV): Linear(in_features=768, out_features=256, bias=False)\n",
      "          (W_DQ): Linear(in_features=768, out_features=256, bias=False)\n",
      "          (W_UK): Linear(in_features=256, out_features=768, bias=False)\n",
      "          (W_UV): Linear(in_features=256, out_features=768, bias=False)\n",
      "          (W_UQ): Linear(in_features=256, out_features=768, bias=False)\n",
      "          (W_KR): Linear(in_features=768, out_features=16, bias=False)\n",
      "          (W_QR): Linear(in_features=256, out_features=192, bias=False)\n",
      "          (output_projection): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (2): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (ff_block): Sequential(\n",
      "        (0): LayerNorm()\n",
      "        (1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        (2): GELU(approximate='none')\n",
      "        (3): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        (4): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (6): Transformer(\n",
      "      (attn): MultiheadLatentAttention(\n",
      "        (W_DKV): Linear(in_features=768, out_features=256, bias=False)\n",
      "        (W_DQ): Linear(in_features=768, out_features=256, bias=False)\n",
      "        (W_UK): Linear(in_features=256, out_features=768, bias=False)\n",
      "        (W_UV): Linear(in_features=256, out_features=768, bias=False)\n",
      "        (W_UQ): Linear(in_features=256, out_features=768, bias=False)\n",
      "        (W_KR): Linear(in_features=768, out_features=16, bias=False)\n",
      "        (W_QR): Linear(in_features=256, out_features=192, bias=False)\n",
      "        (output_projection): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (attn_block): Sequential(\n",
      "        (0): LayerNorm()\n",
      "        (1): MultiheadLatentAttention(\n",
      "          (W_DKV): Linear(in_features=768, out_features=256, bias=False)\n",
      "          (W_DQ): Linear(in_features=768, out_features=256, bias=False)\n",
      "          (W_UK): Linear(in_features=256, out_features=768, bias=False)\n",
      "          (W_UV): Linear(in_features=256, out_features=768, bias=False)\n",
      "          (W_UQ): Linear(in_features=256, out_features=768, bias=False)\n",
      "          (W_KR): Linear(in_features=768, out_features=16, bias=False)\n",
      "          (W_QR): Linear(in_features=256, out_features=192, bias=False)\n",
      "          (output_projection): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (2): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (ff_block): Sequential(\n",
      "        (0): LayerNorm()\n",
      "        (1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        (2): GELU(approximate='none')\n",
      "        (3): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        (4): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (7): Transformer(\n",
      "      (attn): MultiheadLatentAttention(\n",
      "        (W_DKV): Linear(in_features=768, out_features=256, bias=False)\n",
      "        (W_DQ): Linear(in_features=768, out_features=256, bias=False)\n",
      "        (W_UK): Linear(in_features=256, out_features=768, bias=False)\n",
      "        (W_UV): Linear(in_features=256, out_features=768, bias=False)\n",
      "        (W_UQ): Linear(in_features=256, out_features=768, bias=False)\n",
      "        (W_KR): Linear(in_features=768, out_features=16, bias=False)\n",
      "        (W_QR): Linear(in_features=256, out_features=192, bias=False)\n",
      "        (output_projection): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (attn_block): Sequential(\n",
      "        (0): LayerNorm()\n",
      "        (1): MultiheadLatentAttention(\n",
      "          (W_DKV): Linear(in_features=768, out_features=256, bias=False)\n",
      "          (W_DQ): Linear(in_features=768, out_features=256, bias=False)\n",
      "          (W_UK): Linear(in_features=256, out_features=768, bias=False)\n",
      "          (W_UV): Linear(in_features=256, out_features=768, bias=False)\n",
      "          (W_UQ): Linear(in_features=256, out_features=768, bias=False)\n",
      "          (W_KR): Linear(in_features=768, out_features=16, bias=False)\n",
      "          (W_QR): Linear(in_features=256, out_features=192, bias=False)\n",
      "          (output_projection): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (2): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (ff_block): Sequential(\n",
      "        (0): LayerNorm()\n",
      "        (1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        (2): GELU(approximate='none')\n",
      "        (3): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        (4): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (8): Transformer(\n",
      "      (attn): MultiheadLatentAttention(\n",
      "        (W_DKV): Linear(in_features=768, out_features=256, bias=False)\n",
      "        (W_DQ): Linear(in_features=768, out_features=256, bias=False)\n",
      "        (W_UK): Linear(in_features=256, out_features=768, bias=False)\n",
      "        (W_UV): Linear(in_features=256, out_features=768, bias=False)\n",
      "        (W_UQ): Linear(in_features=256, out_features=768, bias=False)\n",
      "        (W_KR): Linear(in_features=768, out_features=16, bias=False)\n",
      "        (W_QR): Linear(in_features=256, out_features=192, bias=False)\n",
      "        (output_projection): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (attn_block): Sequential(\n",
      "        (0): LayerNorm()\n",
      "        (1): MultiheadLatentAttention(\n",
      "          (W_DKV): Linear(in_features=768, out_features=256, bias=False)\n",
      "          (W_DQ): Linear(in_features=768, out_features=256, bias=False)\n",
      "          (W_UK): Linear(in_features=256, out_features=768, bias=False)\n",
      "          (W_UV): Linear(in_features=256, out_features=768, bias=False)\n",
      "          (W_UQ): Linear(in_features=256, out_features=768, bias=False)\n",
      "          (W_KR): Linear(in_features=768, out_features=16, bias=False)\n",
      "          (W_QR): Linear(in_features=256, out_features=192, bias=False)\n",
      "          (output_projection): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (2): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (ff_block): Sequential(\n",
      "        (0): LayerNorm()\n",
      "        (1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        (2): GELU(approximate='none')\n",
      "        (3): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        (4): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (9): Transformer(\n",
      "      (attn): MultiheadLatentAttention(\n",
      "        (W_DKV): Linear(in_features=768, out_features=256, bias=False)\n",
      "        (W_DQ): Linear(in_features=768, out_features=256, bias=False)\n",
      "        (W_UK): Linear(in_features=256, out_features=768, bias=False)\n",
      "        (W_UV): Linear(in_features=256, out_features=768, bias=False)\n",
      "        (W_UQ): Linear(in_features=256, out_features=768, bias=False)\n",
      "        (W_KR): Linear(in_features=768, out_features=16, bias=False)\n",
      "        (W_QR): Linear(in_features=256, out_features=192, bias=False)\n",
      "        (output_projection): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (attn_block): Sequential(\n",
      "        (0): LayerNorm()\n",
      "        (1): MultiheadLatentAttention(\n",
      "          (W_DKV): Linear(in_features=768, out_features=256, bias=False)\n",
      "          (W_DQ): Linear(in_features=768, out_features=256, bias=False)\n",
      "          (W_UK): Linear(in_features=256, out_features=768, bias=False)\n",
      "          (W_UV): Linear(in_features=256, out_features=768, bias=False)\n",
      "          (W_UQ): Linear(in_features=256, out_features=768, bias=False)\n",
      "          (W_KR): Linear(in_features=768, out_features=16, bias=False)\n",
      "          (W_QR): Linear(in_features=256, out_features=192, bias=False)\n",
      "          (output_projection): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (2): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (ff_block): Sequential(\n",
      "        (0): LayerNorm()\n",
      "        (1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        (2): GELU(approximate='none')\n",
      "        (3): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        (4): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (10): Transformer(\n",
      "      (attn): MultiheadLatentAttention(\n",
      "        (W_DKV): Linear(in_features=768, out_features=256, bias=False)\n",
      "        (W_DQ): Linear(in_features=768, out_features=256, bias=False)\n",
      "        (W_UK): Linear(in_features=256, out_features=768, bias=False)\n",
      "        (W_UV): Linear(in_features=256, out_features=768, bias=False)\n",
      "        (W_UQ): Linear(in_features=256, out_features=768, bias=False)\n",
      "        (W_KR): Linear(in_features=768, out_features=16, bias=False)\n",
      "        (W_QR): Linear(in_features=256, out_features=192, bias=False)\n",
      "        (output_projection): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (attn_block): Sequential(\n",
      "        (0): LayerNorm()\n",
      "        (1): MultiheadLatentAttention(\n",
      "          (W_DKV): Linear(in_features=768, out_features=256, bias=False)\n",
      "          (W_DQ): Linear(in_features=768, out_features=256, bias=False)\n",
      "          (W_UK): Linear(in_features=256, out_features=768, bias=False)\n",
      "          (W_UV): Linear(in_features=256, out_features=768, bias=False)\n",
      "          (W_UQ): Linear(in_features=256, out_features=768, bias=False)\n",
      "          (W_KR): Linear(in_features=768, out_features=16, bias=False)\n",
      "          (W_QR): Linear(in_features=256, out_features=192, bias=False)\n",
      "          (output_projection): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (2): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (ff_block): Sequential(\n",
      "        (0): LayerNorm()\n",
      "        (1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        (2): GELU(approximate='none')\n",
      "        (3): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        (4): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (11): Transformer(\n",
      "      (attn): MultiheadLatentAttention(\n",
      "        (W_DKV): Linear(in_features=768, out_features=256, bias=False)\n",
      "        (W_DQ): Linear(in_features=768, out_features=256, bias=False)\n",
      "        (W_UK): Linear(in_features=256, out_features=768, bias=False)\n",
      "        (W_UV): Linear(in_features=256, out_features=768, bias=False)\n",
      "        (W_UQ): Linear(in_features=256, out_features=768, bias=False)\n",
      "        (W_KR): Linear(in_features=768, out_features=16, bias=False)\n",
      "        (W_QR): Linear(in_features=256, out_features=192, bias=False)\n",
      "        (output_projection): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (attn_block): Sequential(\n",
      "        (0): LayerNorm()\n",
      "        (1): MultiheadLatentAttention(\n",
      "          (W_DKV): Linear(in_features=768, out_features=256, bias=False)\n",
      "          (W_DQ): Linear(in_features=768, out_features=256, bias=False)\n",
      "          (W_UK): Linear(in_features=256, out_features=768, bias=False)\n",
      "          (W_UV): Linear(in_features=256, out_features=768, bias=False)\n",
      "          (W_UQ): Linear(in_features=256, out_features=768, bias=False)\n",
      "          (W_KR): Linear(in_features=768, out_features=16, bias=False)\n",
      "          (W_QR): Linear(in_features=256, out_features=192, bias=False)\n",
      "          (output_projection): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (2): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (ff_block): Sequential(\n",
      "        (0): LayerNorm()\n",
      "        (1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        (2): GELU(approximate='none')\n",
      "        (3): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        (4): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (final_norm): LayerNorm()\n",
      "  (out): Linear(in_features=768, out_features=50257, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "627e0019",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (120x64 and 768x16)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      4\u001b[39m model.eval()\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m     response = \u001b[43mtext_generation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m        \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mWho is the first president of the United States?\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_generated_tokens\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m30\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcontext_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mGPT2_CONFIG_124M\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mcontext_length\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1.4\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtop_k\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m20\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mDEVICE\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mResponse:\u001b[39m\u001b[33m\"\u001b[39m, response)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tianyech\\Desktop\\Work\\Personal\\AI\\llm_from_scratch\\llm_utils.py:12\u001b[39m, in \u001b[36mtext_generation\u001b[39m\u001b[34m(model, query, tokenizer, max_generated_tokens, context_size, temperature, top_k, device, alpaca)\u001b[39m\n\u001b[32m      9\u001b[39m input_query = query[:, -context_size:] \u001b[38;5;66;03m# Limits the amount of tokens of each batch to up to context_size\u001b[39;00m\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m     out = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_query\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# Returns [batch, tokens, vocab_size]\u001b[39;00m\n\u001b[32m     14\u001b[39m \u001b[38;5;66;03m# Takes the last row of tokens in the output tensor, becomes [batch, vocab_size]\u001b[39;00m\n\u001b[32m     15\u001b[39m out = out[:, -\u001b[32m1\u001b[39m, :]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tianyech\\.pyenv\\pyenv-win\\versions\\3.11.9\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tianyech\\.pyenv\\pyenv-win\\versions\\3.11.9\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tianyech\\Desktop\\Work\\Personal\\AI\\llm_from_scratch\\SimpleGPT.py:28\u001b[39m, in \u001b[36mSimpleGPT.forward\u001b[39m\u001b[34m(self, inp)\u001b[39m\n\u001b[32m     26\u001b[39m x = token_emb + pos_emb\n\u001b[32m     27\u001b[39m x = \u001b[38;5;28mself\u001b[39m.dropout(x)\n\u001b[32m---> \u001b[39m\u001b[32m28\u001b[39m x = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtransformer_blocks\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     29\u001b[39m x = \u001b[38;5;28mself\u001b[39m.final_norm(x)\n\u001b[32m     30\u001b[39m logits = \u001b[38;5;28mself\u001b[39m.out(x)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tianyech\\.pyenv\\pyenv-win\\versions\\3.11.9\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tianyech\\.pyenv\\pyenv-win\\versions\\3.11.9\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tianyech\\.pyenv\\pyenv-win\\versions\\3.11.9\\Lib\\site-packages\\torch\\nn\\modules\\container.py:240\u001b[39m, in \u001b[36mSequential.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    238\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[32m    239\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m240\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    241\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tianyech\\.pyenv\\pyenv-win\\versions\\3.11.9\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tianyech\\.pyenv\\pyenv-win\\versions\\3.11.9\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tianyech\\Desktop\\Work\\Personal\\AI\\llm_from_scratch\\SimpleGPT.py:91\u001b[39m, in \u001b[36mTransformer.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m     89\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[32m     90\u001b[39m     residual = x\n\u001b[32m---> \u001b[39m\u001b[32m91\u001b[39m     x = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mattn_block\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     92\u001b[39m     x += residual\n\u001b[32m     94\u001b[39m     residual = x\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tianyech\\.pyenv\\pyenv-win\\versions\\3.11.9\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tianyech\\.pyenv\\pyenv-win\\versions\\3.11.9\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tianyech\\.pyenv\\pyenv-win\\versions\\3.11.9\\Lib\\site-packages\\torch\\nn\\modules\\container.py:240\u001b[39m, in \u001b[36mSequential.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    238\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[32m    239\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m240\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    241\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tianyech\\.pyenv\\pyenv-win\\versions\\3.11.9\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tianyech\\.pyenv\\pyenv-win\\versions\\3.11.9\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tianyech\\Desktop\\Work\\Personal\\AI\\llm_from_scratch\\MultiheadLatentAttention.py:54\u001b[39m, in \u001b[36mMultiheadLatentAttention.forward\u001b[39m\u001b[34m(self, x, cache)\u001b[39m\n\u001b[32m     51\u001b[39m Q = Q.view(batch, n_tokens, \u001b[38;5;28mself\u001b[39m.n_heads, \u001b[38;5;28mself\u001b[39m.head_dim).transpose(\u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m)\n\u001b[32m     53\u001b[39m \u001b[38;5;66;03m# Decoupled RoPE\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m54\u001b[39m k_R = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mW_KR\u001b[49m\u001b[43m(\u001b[49m\u001b[43mK\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     55\u001b[39m k_R = \u001b[38;5;28mself\u001b[39m._rope_rotate(k_R)  \u001b[38;5;66;03m# (batch, n_tokens, d_R)\u001b[39;00m\n\u001b[32m     56\u001b[39m k_R = k_R.unsqueeze(\u001b[32m1\u001b[39m).expand(batch, \u001b[38;5;28mself\u001b[39m.n_heads, n_tokens, \u001b[38;5;28mself\u001b[39m.d_R) \u001b[38;5;66;03m# Broadcast to heads\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tianyech\\.pyenv\\pyenv-win\\versions\\3.11.9\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tianyech\\.pyenv\\pyenv-win\\versions\\3.11.9\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tianyech\\.pyenv\\pyenv-win\\versions\\3.11.9\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:125\u001b[39m, in \u001b[36mLinear.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    124\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m125\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mRuntimeError\u001b[39m: mat1 and mat2 shapes cannot be multiplied (120x64 and 768x16)"
     ]
    }
   ],
   "source": [
    "model.to(DEVICE)\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    response = text_generation(\n",
    "        model=model,\n",
    "        query=\"Who is the first president of the United States?\",\n",
    "        tokenizer=tokenizer,\n",
    "        max_generated_tokens=30,\n",
    "        context_size=GPT2_CONFIG_124M['context_length'],\n",
    "        temperature=1.4,\n",
    "        top_k=20,\n",
    "        device=DEVICE\n",
    "    )\n",
    "\n",
    "print(\"Response:\", response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d6da55d",
   "metadata": {},
   "source": [
    "## Fine tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5ed229ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'instruction': 'Give three tips for staying healthy.', 'input': '', 'output': '1.Eat a balanced diet and make sure to include plenty of fruits and vegetables. \\n2. Exercise regularly to keep your body active and strong. \\n3. Get enough sleep and maintain a consistent sleep schedule.'}, {'instruction': 'What are the three primary colors?', 'input': '', 'output': 'The three primary colors are red, blue, and yellow.'}, {'instruction': 'Describe the structure of an atom.', 'input': '', 'output': 'An atom is made up of a nucleus, which contains protons and neutrons, surrounded by electrons that travel in orbits around the nucleus. The protons and neutrons have a positive charge, while the electrons have a negative charge, resulting in an overall neutral atom. The number of each particle determines the atomic number and the type of atom.'}, {'instruction': 'How can we reduce air pollution?', 'input': '', 'output': 'There are a number of ways to reduce air pollution, such as shifting to renewable energy sources, encouraging the use of public transportation, prohibiting the burning of fossil fuels, implementing policies to reduce emissions from industrial sources, and implementing vehicle emissions standards. Additionally, individuals can do their part to reduce air pollution by reducing car use, avoiding burning materials such as wood, and changing to energy efficient appliances.'}, {'instruction': 'Describe a time when you had to make a difficult decision.', 'input': '', 'output': 'I had to make a difficult decision when I was working as a project manager at a construction company. I was in charge of a project that needed to be completed by a certain date in order to meet the client’s expectations. However, due to unexpected delays, we were not able to meet the deadline and so I had to make a difficult decision. I decided to extend the deadline, but I had to stretch the team’s resources even further and increase the budget. Although it was a risky decision, I ultimately decided to go ahead with it to ensure that the project was completed on time and that the client’s expectations were met. The project was eventually successfully completed and this was seen as a testament to my leadership and decision-making abilities.'}]\n"
     ]
    }
   ],
   "source": [
    "alpaca_data = json.load(open(\"alpaca_data.json\", \"r\"))\n",
    "print(alpaca_data[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e0dcd1de",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(len(alpaca_data) * 0.8)\n",
    "test_size = int(len(alpaca_data) * 0.1)\n",
    "val_size = len(alpaca_data) - train_size - test_size\n",
    "\n",
    "dataset = InstructionDataset(alpaca_data, tokenizer)\n",
    "train_dataset, test_dataset, val_dataset = random_split(dataset, [train_size, test_size, val_size])\n",
    "\n",
    "# Pre-fill the collate function with the context length\n",
    "collate_fn = partial(collate_fn, max_context_length=GPT2_CONFIG_124M['context_length'])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, \n",
    "                          batch_size=GPT2_CONFIG_124M['batch_size'],\n",
    "                          collate_fn=collate_fn,\n",
    "                          shuffle=True,\n",
    "                          num_workers=8,\n",
    "                          pin_memory=True)\n",
    "\n",
    "test_loader = DataLoader(test_dataset,\n",
    "                         batch_size=GPT2_CONFIG_124M['batch_size'],\n",
    "                         collate_fn=collate_fn,\n",
    "                         shuffle=False,\n",
    "                         num_workers=8,\n",
    "                         pin_memory=True)\n",
    "\n",
    "val_loader = DataLoader(val_dataset,\n",
    "                        batch_size=GPT2_CONFIG_124M['batch_size'],\n",
    "                        collate_fn=collate_fn,\n",
    "                        shuffle=False,\n",
    "                        num_workers=8,\n",
    "                        pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bce810ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[21106,   318,   281,  ..., 50256, 50256, 50256],\n",
      "        [21106,   318,   281,  ..., 50256, 50256, 50256],\n",
      "        [21106,   318,   281,  ..., 50256, 50256, 50256],\n",
      "        ...,\n",
      "        [21106,   318,   281,  ..., 26411,     0,   628],\n",
      "        [21106,   318,   281,  ..., 50256, 50256, 50256],\n",
      "        [21106,   318,   281,  ..., 50256, 50256, 50256]]), tensor([[  318,   281, 12064,  ...,  -100,  -100,  -100],\n",
      "        [  318,   281, 12064,  ...,  -100,  -100,  -100],\n",
      "        [  318,   281, 12064,  ...,  -100,  -100,  -100],\n",
      "        ...,\n",
      "        [  318,   281, 12064,  ...,     0,   628, 50256],\n",
      "        [  318,   281, 12064,  ...,  -100,  -100,  -100],\n",
      "        [  318,   281, 12064,  ...,  -100,  -100,  -100]])]\n"
     ]
    }
   ],
   "source": [
    "print(next(iter(train_loader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4053b891",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37 669\n"
     ]
    }
   ],
   "source": [
    "print(len(min(val_loader.dataset, key=lambda x: len(x))), len(max(val_loader.dataset, key=lambda x: len(x))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e76bcfea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task\n",
      "Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Give three tips for staying healthy.\n",
      "\n",
      "\n",
      "\n",
      "Step 2\n",
      "\n",
      "Include as many items as possible:\n",
      "\n",
      "A good body temperature\n",
      "\n",
      "A well fed diet\n",
      "\n",
      "Caffeine supplementation on active eating\n",
      "\n",
      "Dieting a healthy diet regularly\n",
      "\n",
      "Keeping healthy in the gym\n"
     ]
    }
   ],
   "source": [
    "test_text = to_alpaca_format(alpaca_data[0])\n",
    "\n",
    "res = text_generation(model=model,\n",
    "                     query=test_text,\n",
    "                     tokenizer=tokenizer,\n",
    "                     max_generated_tokens=50,\n",
    "                     context_size=GPT2_CONFIG_124M['context_length'],\n",
    "                     temperature=1.4,\n",
    "                     top_k=20,\n",
    "                     device=DEVICE)\n",
    "\n",
    "print(test_text)\n",
    "print(res[0][len(test_text):])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "05159242",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.00005, weight_decay=0.01)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc0f196",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 - 2, train_loss: 2.988710567965413, val_loss: 2.9911671506441557\n",
      "Epoch: 0 - 4, train_loss: 2.626174870029685, val_loss: 2.6297641192949737\n",
      "Epoch: 0 - 6, train_loss: 2.3467894093253663, val_loss: 2.3518476427518404\n",
      "Epoch: 0 - 8, train_loss: 2.1436020390296573, val_loss: 2.149673807804401\n",
      "Epoch: 0 - 10, train_loss: 1.9918972559099908, val_loss: 1.9991346045640799\n",
      "Epoch: 0 - 12, train_loss: 1.9281936444312053, val_loss: 1.9356513654268706\n",
      "Epoch: 0 - 14, train_loss: 1.8986405657245846, val_loss: 1.9057244638296273\n",
      "Epoch: 0 - 16, train_loss: 1.8723402119122934, val_loss: 1.8795431436025178\n",
      "Epoch: 0 - 18, train_loss: 1.8429103487387366, val_loss: 1.8498335020358745\n",
      "Epoch: 0 - 20, train_loss: 1.8239694289853081, val_loss: 1.8318410557966966\n",
      "Epoch: 0 - 22, train_loss: 1.8187418733278482, val_loss: 1.82621607707097\n",
      "Epoch: 0 - 24, train_loss: 1.8062148175086454, val_loss: 1.8138213025606595\n",
      "Epoch: 0 - 26, train_loss: 1.7988520615423123, val_loss: 1.8072266184366665\n",
      "Epoch: 0 - 28, train_loss: 1.8013571659616956, val_loss: 1.810040151339311\n",
      "Epoch: 0 - 30, train_loss: 1.8008931244457944, val_loss: 1.809433631346776\n",
      "Epoch: 0 - 32, train_loss: 1.7927732509137393, val_loss: 1.8013720941543578\n",
      "Epoch: 0 - 34, train_loss: 1.777839537080355, val_loss: 1.786246217764341\n",
      "Epoch: 0 - 36, train_loss: 1.765926841909302, val_loss: 1.7746912407875062\n",
      "Epoch: 0 - 38, train_loss: 1.7650410580282097, val_loss: 1.7732820503528302\n",
      "Epoch: 0 - 40, train_loss: 1.7601333774756616, val_loss: 1.7696788008396442\n",
      "Epoch: 0 - 42, train_loss: 1.751490160905955, val_loss: 1.760616060953874\n",
      "Epoch: 0 - 44, train_loss: 1.748819488879466, val_loss: 1.7584199771514306\n",
      "Epoch: 0 - 46, train_loss: 1.7507445938058643, val_loss: 1.7596737362788273\n",
      "Epoch: 0 - 48, train_loss: 1.7498794181418864, val_loss: 1.7593159185923062\n",
      "Epoch: 0 - 50, train_loss: 1.7440985598213006, val_loss: 1.7543327810214115\n",
      "Epoch: 0 - 52, train_loss: 1.7407776344008135, val_loss: 1.7509678099705623\n",
      "Epoch: 0 - 54, train_loss: 1.7396324414905275, val_loss: 1.750605599146623\n",
      "Epoch: 0 - 56, train_loss: 1.7385203834451912, val_loss: 1.7487579351205091\n",
      "Epoch: 0 - 58, train_loss: 1.7336532725345353, val_loss: 1.7446105751624474\n",
      "Epoch: 0 - 60, train_loss: 1.7294184663529075, val_loss: 1.7400904400532062\n",
      "Epoch: 0 - 62, train_loss: 1.7265063306272683, val_loss: 1.736614919442397\n",
      "Epoch: 0 - 64, train_loss: 1.723214094351402, val_loss: 1.733831494954916\n",
      "Epoch: 0 - 66, train_loss: 1.7220223999738555, val_loss: 1.7329043388366698\n",
      "Epoch: 0 - 68, train_loss: 1.722567198460342, val_loss: 1.7337063154807457\n",
      "Epoch: 0 - 70, train_loss: 1.723487580058621, val_loss: 1.734902475980612\n",
      "Epoch: 0 - 72, train_loss: 1.723653308865291, val_loss: 1.7348635187515846\n",
      "Epoch: 0 - 74, train_loss: 1.7207708069279295, val_loss: 1.7328243723282448\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m      \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m      \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m      \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m=\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m      \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m      \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m      \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mDEVICE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m      \u001b[49m\u001b[43mn_epochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m      \u001b[49m\u001b[43meval_freq\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m      \u001b[49m\u001b[43mearly_stop\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tianyech\\Desktop\\Work\\Personal\\AI\\llm_from_scratch\\llm_utils.py:69\u001b[39m, in \u001b[36mtrain\u001b[39m\u001b[34m(model, train_loader, val_loader, optimizer, criterion, device, n_epochs, tokenizer, eval_freq, early_stop)\u001b[39m\n\u001b[32m     67\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m step % eval_freq == \u001b[32m0\u001b[39m:\n\u001b[32m     68\u001b[39m     model.eval()\n\u001b[32m---> \u001b[39m\u001b[32m69\u001b[39m     train_loss = \u001b[43mcalc_total_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     70\u001b[39m     val_loss = calc_total_loss(model, val_loader, criterion, device)\n\u001b[32m     72\u001b[39m     tokens_seen_at_step.append(tokens_seen)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tianyech\\Desktop\\Work\\Personal\\AI\\llm_from_scratch\\llm_utils.py:46\u001b[39m, in \u001b[36mcalc_total_loss\u001b[39m\u001b[34m(model, loader, criterion, device)\u001b[39m\n\u001b[32m     44\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m input_batch, target_batch \u001b[38;5;129;01min\u001b[39;00m loader:\n\u001b[32m     45\u001b[39m     loss = calc_batch_loss(input_batch, target_batch, model, criterion, device)\n\u001b[32m---> \u001b[39m\u001b[32m46\u001b[39m     total_loss += \u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     48\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m total_loss / \u001b[38;5;28mlen\u001b[39m(loader)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "train_losses, val_losses, tokens_seen = train(model=model,\n",
    "      train_loader=train_loader,\n",
    "      val_loader=test_loader,\n",
    "      optimizer=optimizer,\n",
    "      criterion=criterion,\n",
    "      tokenizer=tokenizer,\n",
    "      device=DEVICE,\n",
    "      n_epochs=1,\n",
    "      eval_freq=10,\n",
    "      early_stop=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f9fee9b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.save(model.state_dict(), \"simple_gpt_117M.pth\")\n",
    "model.load_state_dict(torch.load(\"simple_gpt_117M.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ecb81aff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task\n",
      "Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Give three tips for staying healthy.\n",
      "\n",
      "\n",
      "<|endoftext|>It was just before Thanksgiving weekend, and I thought I'd start writing a story I thought I'd never have time for. I've been feeling pretty good lately and want to continue doing well. So, after an hourlong break, what would\n"
     ]
    }
   ],
   "source": [
    "test_text = to_alpaca_format(alpaca_data[0])\n",
    "\n",
    "res = text_generation(model=model,\n",
    "                     query=test_text,\n",
    "                     tokenizer=tokenizer,\n",
    "                     max_generated_tokens=50,\n",
    "                     context_size=GPT2_CONFIG_124M['context_length'],\n",
    "                     temperature=1.4,\n",
    "                     top_k=20,\n",
    "                     device=DEVICE)\n",
    "\n",
    "print(test_text)\n",
    "print(res[0][len(test_text):])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.11.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
